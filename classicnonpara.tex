\documentclass[12pt]{jsarticle}
%\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
%\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{古典的なノンパラメトリック検定はなにを仮定しているのか}
\author{}
%\date{}                                           % Activate to display a given date or no date

\begin{document}
\maketitle
\section{前置き}

もともと工学部出身のぼくが, 医学系の研究室に行っておもしろかったことはいろいろある. 

その中の一つが, 医学系の人のアーチファクト（artifact）という言葉の使い方だ. 

アーチファクトというのは, 辞書的には人工物とか工芸品を指す.

ぼくからしたら「この結果はアーチファクトだよ」とか言われたら褒められているのかな？　みたいな感じがする.

でも違う. 医学系の言葉使いではアーチファクトというのは, 自然現象とか生命現象の本質じゃない人工的な混ざりもの, みたいなニュアンスだ.

ところで, ぼくは統計モデリングというのが好きだ. モデリングというのはデータを取った人からいろいろ話を聞いて, 関数とか確率分布とか微分方程式とか差分方程式とかを組み合わせて, データを取った人のイメージとか目的とかを統計の言葉に翻訳するような作業だ. モデルを作るというのは, ぼくの感覚では仮定を置くことに等しい. 

それはもうアーチファクトのかたまりみたいな作業だ.

そのせいかどうかは知らないが, 医学系の人はモデリングよりも検定が好きな印象がある. 統計屋というと, いろんな検定を知っていて, 場合に応じて正しい検定を選べる人, みたいな認識をされることもある.

なかでもノンパラメトリック検定が好きなようだ. 

ノンパラメトリック検定とは, 母集団に対して特定の確率分布を仮定しないで検定をする手法の総称とされる. 

仮定が少ないほうが客観的な分析でえらいという感覚があるんだと思う.

そこがぼくの好みと相容れない. 

でも好みじゃないのでノンパラメトリック検定に関する相談には乗りませんというのも大人げないので, これからちょっとノンパラメトリック検定について勉強していきたいと思っている.

この文書はそういったものだ. 

この文書がこれからどういったものになるかは, ぼくもまだわかってない.

でも結びの言葉はなんとなくだけど決めてある. 

「仮定を置かないんじゃなくて仮定を明確にして, アーチファクトをもってアーチファクトを制すのだ.」

\section{ノンパラメトリック・モデル}

ノンパラメトリックモデルという言葉とノンパラメトリック検定という言葉はまったく別物だと思ったほうがよさそうだ.

ノンパラメトリックモデルというのは, パラメータが多すぎるモデルのことを指す.

データのサイズにほぼ比例して, モデルのパラメータが増えるようなモデルはノンパラメトリックモデルと呼ばれる. 

以下では, ノンパラメトリックモデルの話はしない. 

ノンパラメトリック検定の話をする. 

\section{仮説検定一般に関する注意点}

仮説検定は「確率版背理法」と例えられることもあるが, 現実のデータを扱う以上, 背理法のようにすっきりとはしていない.
仮説検定では, 「帰無仮説 $H_0: \theta = 0$, 対立仮説 $H_1: \theta \neq 0$」みたいな形で「仮説」を提示する. 
しかし, 帰無仮説 $H_0$ の確率を評価するのに, 帰無分布というのを作らなくちゃいけない.

仮説検定には, 「$H_0: \theta = 0$」といった\textbf{意識されやすい仮定}と検定のやり方（何検定を使うか）を決めた時点で置かれている\textbf{意識されにくい仮定}が存在する. 例えば「○○検定を行った」と言った時点で, 「サンプルは正規分布に従う」とか「サンプルは独立同分布とする」とかの意識されにくい仮定はクリアされたことになっている. 

仮説検定を行った結果, 帰無仮説が棄却されたというと意識されやすい仮定が棄却された感じがするが, 実は意識されにくい仮定のほうがもっとずれていたのかもしれない.

「$H_0$でないから$H_1$だ」という背理法ほど, 仮説検定はすっきりしていない.

\section{符号検定（Sign Test）}

検定というのは帰無分布を一つ決めて, そこからのずれを測っている. 

帰無分布を決めなきゃいけないのに, 「特定の確率分布を仮定しない」なんてことができるのか. 

どうやらできるようだ.

サンプル $X_1, X_2, \ldots, X_n$ を生成した分布が連続型の分布関数 $F$ を持つということだけを仮定しよう. これはどちらかというと意識されにくい仮定だ.$\theta$ を $F$ の中央値とする. 

その上で母集団の中央値が0であるという帰無仮説を検定したい. 
まず, 帰無仮説 $H_0: \theta = 0$, 対立仮説 $H_1: \theta > 0$ の片側検定を考える.

そして, 
\begin{align}
S_n = \sum_{i=1}^{n} I_{\{X_i > 0\}}
\end{align}
という統計量を作ることにする. ここで $I_A$ は指示関数（つまり $X_i > 0$ なら 1, さもなくば 0 を返す）である. 

$S_n$ は符号が + になった回数を単に数えただけだ. 

帰無仮説のもとで, $S_n$ は二項分布 $\mathrm{Binomial}(n, 1/2)$ に従う.
帰無仮説のもとで $A$ という事象の起こる確率を $\Pr_{H_0}(A)$ と書くことにすると, この検定の有意水準 $\alpha$ での棄却域は, $\Pr_{H_0}(S_n>k)\le\alpha$ を満たす $k$に対して$S_n>k$ となる範囲である.

対立仮説 $H_1: \theta < 0$ の片側検定をやりたい場合, 棄却域は, $\Pr_{H_0}(S_n<k)\le\alpha$ を満たす $k$に対して$S_n>k$ となる範囲である.

対立仮説 $H_1: \theta \neq 0$ の両側検定をやりたい場合, 棄却域は, $\Pr_{H_0}(\min(S_n,n-S_n)<k)\le\alpha/2\}$ を満たす $k$に対して$S_n<k$ となる範囲である.

中央値が0である場合だけでなく, 一般の $\theta_0$ の検定を考えたいときは, $X_i$ それぞれから $\theta_0$ を引いてやれば, 同じ問題に帰着される. 

2群の比較ならわかるけど, 1群の検定なんて使う場面あるのかと思うかもしれないので, こんな例を与えておく：「患者さんたちにある睡眠薬を飲ませたところ，　睡眠時間がそれぞれ増えたり減ったりしました. 睡眠時間の増減の中央値が0より大きけば, 睡眠薬は効果ありと言えそうです.」

\subsection{Rによる実装例}

統計ソフト R で上記の符号検定のp値を計算するには, 次のように書けばよい.
まず, 対立仮説 $H_1: \theta > 0$ の片側検定の場合,
\begin{verbatim}
theta0 <- 0
n <- length(X)
Sn <- sum(X>theta0)
pbinom(Sn-1,n,0.5,lower.tail = FALSE)
\end{verbatim}
対立仮説 $H_1: \theta > 0$ の片側検定の場合, 
\begin{verbatim}
pbinom(Sn-1,n,0.5,lower.tail = FALSE)
\end{verbatim}
対立仮説 $H_1: \neq  0$ の両側検定の場合, 
\begin{verbatim}
2*pbinom(min(Sn,n-Sn),n,0.5)
\end{verbatim}
こう書いても同じ.
\begin{verbatim}
2*min(pbinom(Sn-1,n,0.5,lower.tail = FALSE),pbinom(Sn,n,0.5))
\end{verbatim}

\section{Wilcoxon の符号付き順位検定(Wilcoxon Signed-Rank Test)}

$R_i$ をサンプル $X_i$ の順位とする.
フォーマルに書くと,
\begin{align}
R_i = \#\{j;X_j \le X_i\}
\end{align}
である. ここで, $\#A$ は集合 $A$ の 要素の個数を返す関数である.

ここで分布 $F$ の密度関数が左右対称であるという仮定をする. これはどちらかというと意識されにくい仮定だ.
まず, 帰無仮説 $H_0: \theta = 0$, 対立仮説 $H_1: \theta > 0$ の片側検定を考える.

\subsection{シミュレーション}

\end{document}  